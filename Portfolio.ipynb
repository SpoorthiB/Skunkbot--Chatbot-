{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A chatbot for AI Skunkworks - SkunkBot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims at creating a chatbot named SkunkBot in Slack for AI Skunkworks, a group of people at Northeastern University who research and develop Artificial Intelligence, Machine Learning, and Deep Learning projects primarily for the sake of innovation and learning. The chatbot is trained to answer all the questions related to AI Skunkworks such as the purpose and projects. The chatbot is created by integrating Google Cloud Platform to DialogFlow API and then integrating it with Slack. Three phases are carried out. In the first phase, the knowledge base for the data is created. The data is preprocessed by performing semi-structured analysis and stored on Google Cloud Datastore. Also, the synonyms for all these extracted topics are created using Natural Language Processing (NLP). In the second phase, a chatbot is built using DialogFlow. The topic entries from Cloud Datastore are imported into DialogFlow to populate entity.  After gathering all the data to train the chatbot, intents are created to capture request response action between the chatbot and a user and training phases are added to train a chatbot intent. API/REST web-service is published that maps to DialogFlow’s specification for webhooks. The webhook is published on the internet by using ngrok service to create an HTTPs tunnel from service running behind GCP firewall to a public URL on the internet. The webhook is enabled and HTTPs tunnel is mentioned in the fulfillment section of the DialogFlow API. In the third and the final phase, the DialogFlow is integrated to Slack app, the DialogFlow contains an inbuilt integration platform for Slack. Finally, we test the bot in Slack app by asking it the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial Intelligence is growing day by day and chatbots are a big part of this growth. Many companies have started using chatbots as a medium for automated customer support. Using chatbots is not only convenient but very helpful to huge companies in terms of labor cost. A chatbot is an AI-powered piece of software in a device, application, website or other networks that try to estimate a consumer’s needs and then assist them to perform a task. It is forecasted by Gartner that by 2020, over 85% of customer interactions will be handled without a human. A chatbot consists of three main NLP categories: Entities, Intents, and Actions. Entities are specific mappings of natural language word combinations in the human conversations to standard phases conveying their clear meaning. Intents are general characteristics that map the user’s input to the corresponding action. For example, the input “Can I work on a skunkworks project?” will map to ‘Skunkwork_projects’ intent by its entire wording. Actions are the responses to the corresponding intents. These are usually the conventional functions, which may take optional parameters from the caller with context. API are annotation for application programming interface which are a set of functions and procedures that allow the creation of applications which access the features or data of an operating system, application, or other service. API calls are used retrieve data either in XML, JSON or Excel format. This format forms the basic blocks to create the ontology template. A chatbot can be created using various APIs such as DialogFlow/api.ai, wit.ai, Rasa, Msg.ai, etc. A DialogFlow API is a Google-owned product that does not require installation and the data is hosted on cloud. It provides integration with various services such as Google Assistant, Skype, Slack, FB Messenger, etc. A chatbot intent creation consists of two main tasks: Training and Classification. In the training task, the training data with word embedding and the known labeled data are input to Machine Learning algorithms. In the classification task, the user text input along with word embedding is passed to a model which also takes as an input the algorithms from training task. This model then gives an intent/label. Figure 1. shows the block diagram for the same \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"flow1.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-structured analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we extract topic headings and associated text from the file and store this information as key-value pairs in Cloud Database to give the chatbot a basic vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n",
      "Requirement already satisfied: google-cloud-datastore in /usr/local/envs/py2env/lib/python2.7/site-packages (1.7.3)\n",
      "Requirement already satisfied: google-cloud-core<0.30dev,>=0.29.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-datastore) (0.29.1)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.6.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-datastore) (1.9.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (3.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (1.5.5)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (2.18.4)\n",
      "Requirement already satisfied: futures>=3.2.0; python_version < \"3.2\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (3.2.0)\n",
      "Requirement already satisfied: pytz in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (2018.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (1.10.0)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (40.6.3)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (1.6.2)\n",
      "Requirement already satisfied: grpcio>=1.8.2; extra == \"grpc\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (1.17.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (2018.11.29)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (0.2.2)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (2.1.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (3.4.2)\n",
      "Requirement already satisfied: enum34>=1.0.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from grpcio>=1.8.2; extra == \"grpc\"->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (1.1.6)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "# Installing the google cloud datastore\n",
    "!pip install google-cloud-datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datastore_client ia a variable which stores the values to be store in Cloud Datastore\n",
    "datastore_client = datastore.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a line of text consisting of less than 5 words is followed by paragraphs of text the assume the line of text with less than 5 words is a topic (i.e. the topic of a question an employee might ask) and that the paragraphs of text are the answer to that question (called action_text for the lack of a better term).\n",
    "\n",
    "When a topic and action_text are found these are stored in Cloud Datastore as a key-value pair with the topic as the key and the action_text as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ﻿skunkwork project: A skunkworks project is a project developed by a small and loosely structured group of people who research and develop a project primarily for the sake of radical innovation. \n",
      "\n",
      "Saved ai skunkwork: AI Skunkworks at Northeastern University is a group of people who research and develop Artificial Intelligence, Machine Learning, and Deep Learning projects primarily for the sake of innovation and learning. We provide open-mic, mentorship, workshops, seminars, hack-a-thons, and events that assist those exploring the edges of AI.\n",
      "\n",
      "Saved social butterfly: Social Butterfly is social engagement software using NEU AI Skunkworks(or you can choose\n",
      "something else) as a model. In this you will develop models that enhance one of the five aspects of\n",
      "\n",
      "Saved *profile community members: Create statistical profiles of the NEU AI Skunkworks community.\n",
      "\n",
      "Saved *publish on social media: Create and approve content for multiple social networks and accounts. Create models that will\n",
      "optimize the timing and customization of content to different social media cultures.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skunk = open('skunk.txt', 'r')\n",
    "while True:\n",
    "  \n",
    "  topic = skunk.readline()\n",
    "  if not(topic):\n",
    "    break\n",
    "  \n",
    "  if (topic != '\\r\\n') and (len(topic.split(' ')) < 5):\n",
    "  \n",
    "    action_text = ''\n",
    "        \n",
    "    last_line = ''\n",
    "    line = skunk.readline()\n",
    "    \n",
    "    while (last_line != '\\r\\n') and (line != '\\r\\n') and (len(line.split(' ')) > 5):\n",
    "      \n",
    "      action_text += line\n",
    "      last_line = line\n",
    "      line = skunk.readline()\n",
    "      \n",
    "    if action_text != '':\n",
    "      \n",
    "      kind = 'Topic'\n",
    "      topic_key = datastore_client.key(kind, topic.strip().lower())\n",
    "      \n",
    "      topic = datastore.Entity(key=topic_key)\n",
    "      topic['action_text'] = action_text\n",
    "\n",
    "      datastore_client.put(topic)\n",
    "\n",
    "      print('Saved {}: {}'.format(topic.key.name, topic['action_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing incrorrect words and synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorrectly tagged questions are hard to find and answer. If you know of common, alternate spellings or phrasings for this tag, add them here so we can automatically correct them in the future. For example, suggest “Skunkworks” as a synonym for AI Skunkworks, or “Projects” for project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import inflect() for Plurals\n",
    "The methods of the class engine in module inflect.py provide plural inflections, singular noun inflections, “a”/”an” selection for English words, and manipulation of numbers as words.\n",
    "Plural forms of all nouns, most verbs, and some adjectives are provided. Where appropriate, “classical” variants (for example: “brother” -> “brethren”, “dogma” -> “dogmata”, etc.) are also provided.\n",
    "Single forms of nouns are also provided. The gender of singular pronouns can be chosen (for example “they” -> “it” or “she” or “he” or “they”).\n",
    "Pronunciation-based “a”/”an” selection is provided for all English words, and most initialisms.\n",
    "It is also possible to inflect numerals (1,2,3) to ordinals (1st, 2nd, 3rd) and to English words (“one”, “two”, “three”).\n",
    "In generating these inflections, inflect.py follows the Oxford English Dictionary and the guidelines in Fowler’s Modern English Usage, preferring the former where the two disagree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n",
      "Requirement already satisfied: inflect in /usr/local/envs/py2env/lib/python2.7/site-packages (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install inflect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stop words: stop words are words which are filtered out before or after processing of natural language data (text).[1] Though \"stop words\" usually refers to the most common words in a language, there is no single universal list of stop words used by all natural language processing tools, and indeed not all tools even use such a list. Some tools specifically avoid removing these stop words to support phrase search. \n",
    "- Any group of words can be chosen as the stop words for a given purpose. For some search engines, these are some of the most common, short function words, such as the, is, at, which, and on. In this case, stop words can cause problems when searching for phrases that include them, particularly in names such as \"The Who\", \"The The\", or \"Take That\". Other search engines remove some of the most common words including lexical words, such as \"want\" from a query in order to improve performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /content/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /content/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = datastore.Client()\n",
    "query = client.query(kind='Topic')\n",
    "results = list(query.fetch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "plurals = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/ipykernel/__main__.py:2: DeprecationWarning: the sets module is deprecated\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*profile community members *profile Set([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/unidecode/__init__.py:46: RuntimeWarning: Argument <type 'str'> is not an unicode object. Passing an encoded string will likely have unexpected results.\n",
      "  _warn_if_not_unicode(string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*profile community members community Set([u'communities', u'community'])\n",
      "*profile community members members Set([u'phalluses', u'penises', u'extremity', u'appendages', u'member', u'penis', u'members', u'appendage', u'extremities', u'phallus'])\n",
      "*publish on social media *publish Set([])\n",
      "*publish on social media social Set([])\n",
      "*publish on social media media Set([u'spiritualists', u'medium', u'sensitive', u'sensitives', u'spiritualist', u'metiers', u'mediums', u'metier'])\n",
      "ai skunkwork ai Set([u'AI', u'ai', u'ais', u'AIS'])\n",
      "ai skunkwork skunkwork Set([])\n",
      "social butterfly social Set([])\n",
      "social butterfly butterfly Set([u'butterfly', u'butterflies'])\n",
      "﻿skunkwork project ﻿skunkwork Set([])\n",
      "﻿skunkwork project project Set([u'task', u'projection', u'undertaking', u'labors', u'labor', u'project', u'tasks', u'projections', u'undertakings', u'projects'])\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from sets import Set\n",
    "\n",
    "for result in results:\n",
    "  for word in result.key.name.split():\n",
    "    \n",
    "    if word in stop:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    synonyms = Set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "      \n",
    "      if \".n.\" in str(syn):\n",
    "\n",
    "        for l in syn.lemmas():\n",
    "          lemma = l.name()\n",
    "          if (lemma.isalpha()):\n",
    "            synonyms.add(lemma)\n",
    "            synonyms.add(plurals.plural(lemma))\n",
    "      \n",
    "      if \".a.\" in str(syn):\n",
    "        synonyms = Set()\n",
    "        break\n",
    "\n",
    "    print result.key.name, word, synonyms\n",
    "    \n",
    "    kind = 'Synonym'\n",
    "    synonym_key = datastore_client.key(kind, result.key.name)\n",
    "\n",
    "    synonym = datastore.Entity(key=synonym_key)\n",
    "    synonym['synonym'] = result.key.name\n",
    "\n",
    "    datastore_client.put(synonym)\n",
    "    \n",
    "    synonym_key = datastore_client.key(kind, word)\n",
    "\n",
    "    synonym = datastore.Entity(key=synonym_key)\n",
    "    synonym['synonym'] = result.key.name\n",
    "\n",
    "    datastore_client.put(synonym)\n",
    "    \n",
    "    for dictionary_synonym in synonyms:\n",
    "      \n",
    "      synonym_key = datastore_client.key(kind, dictionary_synonym)\n",
    "\n",
    "      synonym = datastore.Entity(key=synonym_key)\n",
    "      synonym['synonym'] = result.key.name\n",
    "\n",
    "      datastore_client.put(synonym)\n",
    "      \n",
    "    synonym_key = datastore_client.key(kind, plurals.plural(word))\n",
    "\n",
    "    synonym = datastore.Entity(key=synonym_key)\n",
    "    synonym['synonym'] = result.key.name\n",
    "\n",
    "    datastore_client.put(synonym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n",
      "Requirement already up-to-date: pip in /usr/local/envs/py2env/lib/python2.7/site-packages (19.1)\n",
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n",
      "Requirement already satisfied: dialogflow==0.3.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (0.3.0)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=0.1.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from dialogflow==0.3.0) (1.9.0)\n",
      "Requirement already satisfied: googleapis-common-protos[grpc]<2.0dev,>=1.5.2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from dialogflow==0.3.0) (1.5.5)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (3.6.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (2.18.4)\n",
      "Requirement already satisfied: futures>=3.2.0; python_version < \"3.2\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (3.2.0)\n",
      "Requirement already satisfied: pytz in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (2018.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (1.10.0)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (40.6.3)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (1.6.2)\n",
      "Requirement already satisfied: grpcio>=1.8.2; extra == \"grpc\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (1.17.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (2018.11.29)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (0.2.2)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (2.1.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (3.4.2)\n",
      "Requirement already satisfied: enum34>=1.0.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from grpcio>=1.8.2; extra == \"grpc\"->google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (1.1.6)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=0.1.4->dialogflow==0.3.0) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install dialogflow==0.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DialogFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dialogflow by itself is a platform service that allows developers to build “engaging voice and text based conversational interfaces powered by AI”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Dialogflow?\n",
    "We are Aiming to create a slack channel which can easily integrate with Dialogflow which is provides one-click integrations to most popular messaging Apps like Facebook Messenger, Slack, Twitter, Kik, Line, Skype, Telegram, Twilio and Viber. Even to some voice assistants like Google Assistant, Amazon Alexa and Microsoft Cortana. So in future even if we need a facebookbot or a bot anywhere for AI Skunkworks we can easily integrate it. Also, Dialogflow service has become free and available to Google Cloud Platform users. And we did our coding part in GCP.\n",
    "\n",
    "- Compared to some platforms which works on predefined questions like Chatfuel, Dialogflow can offer better user experience with NLP. DialogFlow Agents are pretty good at NLP.\n",
    "- Entities: These are the knowledge repository that the agent would use to answer the user’s question. There are a variety of entities: system entities to include information about time etc, weather/location entities etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = datastore.Client()\n",
    "query = client.query(kind='Topic')\n",
    "results = list(query.fetch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[value: \"*profile community members\"\n",
      "synonyms: \"*profile community members\"\n",
      ", value: \"*publish on social media\"\n",
      "synonyms: \"*publish on social media\"\n",
      ", value: \"ai skunkwork\"\n",
      "synonyms: \"ai skunkwork\"\n",
      ", value: \"social butterfly\"\n",
      "synonyms: \"social butterfly\"\n",
      ", value: \"\\357\\273\\277skunkwork project\"\n",
      "synonyms: \"\\357\\273\\277skunkwork project\"\n",
      "]\n",
      "Entity created: <google.api_core.operation.Operation object at 0x7f40ebc0ccd0>\n"
     ]
    }
   ],
   "source": [
    "import dialogflow\n",
    "\n",
    "entity_types_client = dialogflow.EntityTypesClient()\n",
    "\n",
    "project_id = !(gcloud config get-value project)\n",
    "\n",
    "project_agent_path = entity_types_client.project_agent_path(\n",
    "        project_id[0])\n",
    "\n",
    "for element in entity_types_client.list_entity_types(project_agent_path):\n",
    "  if (element.display_name == 'Topic'):\n",
    "    entity_type_path = element.name\n",
    "\n",
    "project_id = !(gcloud config get-value project)\n",
    "\n",
    "entities = []\n",
    "\n",
    "for result in results:\n",
    "  \n",
    "  entity = dialogflow.types.EntityType.Entity()\n",
    "  entity.value = result.key.name\n",
    "  entity.synonyms.append(result.key.name)\n",
    "\n",
    "  entities.append(entity)\n",
    "\n",
    "print entities\n",
    "\n",
    "response = entity_types_client.batch_create_entities(\n",
    "        entity_type_path, entities)\n",
    "\n",
    "print('Entity created: {}'.format(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webhook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API/REST web-service is published that maps to DialogFlow’s specification for webhooks. The webhook is published on the internet by using ngrok service to create an HTTPs tunnel from service running behind GCP firewall to a public URL on the internet. The webhook is enabled and HTTPs tunnel is mentioned in the fulfillment section of the DialogFlow API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n",
      "Requirement already satisfied: flask in /usr/local/envs/py2env/lib/python2.7/site-packages (0.11.1)\n",
      "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/envs/py2env/lib/python2.7/site-packages (from flask) (1.1.0)\n",
      "Requirement already satisfied: click>=2.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from flask) (7.0)\n",
      "Requirement already satisfied: Jinja2>=2.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from flask) (2.8)\n",
      "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/envs/py2env/lib/python2.7/site-packages (from flask) (0.14.1)\n",
      "Requirement already satisfied: MarkupSafe in /usr/local/envs/py2env/lib/python2.7/site-packages (from Jinja2>=2.4->flask) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from flask import Flask, request, jsonify, make_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the webhook is running on port 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/webhook/', methods=['POST'])\n",
    "def handle():\n",
    "    req = request.get_json(silent=True, force=True)\n",
    "    print 'Request:'\n",
    "    print(json.dumps(req, indent=4))\n",
    "    if req.get('queryResult').get('action') != 'lookup':\n",
    "        return {}\n",
    "    topic = req.get('queryResult').get('parameters').get('Topic')\n",
    "    topic = re.sub(r'[^\\w\\s]', '', topic)\n",
    "    print topic\n",
    "    rsp = getResponse(topic)\n",
    "    rsp = json.dumps(rsp, indent=4)\n",
    "    print rsp\n",
    "    r = make_response(rsp)\n",
    "    r.headers['Content-Type'] = 'application/json'\n",
    "    return r\n",
    "\n",
    "def getResponse(topic):\n",
    "    \n",
    "    client = datastore.Client()\n",
    "    query = client.query(kind='Synonym')\n",
    "    key = client.key('Synonym', topic)\n",
    "    query.key_filter(key, '=')\n",
    "    results = list(query.fetch())\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        return buildReply('I can\\'t find that in the handbook...')\n",
    "    \n",
    "    print results[0]['synonym']\n",
    "    \n",
    "    query = client.query(kind='Topic')\n",
    "    key = client.key('Topic', results[0]['synonym'])\n",
    "    query.key_filter(key, '=')\n",
    "    results = list(query.fetch())\n",
    "    \n",
    "    print results[0]['action_text']\n",
    "    \n",
    "    return buildReply(results[0]['action_text'])\n",
    "\n",
    "def buildReply(info):\n",
    "    return {\n",
    "        'fulfillmentText': info,\n",
    "    }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The ngrok file is separately attached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that DialogFlow proves to be a great API to create a chatbot compared to other platforms. Using the Analytics components, it can be concluded that the SkunkBot responds 16.5% incorrectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=analytics.JPG>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://dialogflow.com/\n",
    "- https://en.wikipedia.org/wiki/Chatbot#Limitations_of_Chatbots\n",
    "- https://cloud.google.com/solutions\n",
    "- https://www.analyticsvidhya.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright <2019> <SPOORTHI BELLAM ><PRACHI PATEL>\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "All writing in the document is licensed bt The Creative Commons Attribution 3.0 https://creativecommons.org/licenses/by/3.0/us/.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
